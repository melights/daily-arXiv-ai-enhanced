{"id": "2511.07654", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07654", "abs": "https://arxiv.org/abs/2511.07654", "authors": ["Yinsen Jia", "Boyuan Chen"], "title": "Time-Aware Policy Learning for Adaptive and Punctual Robot Control", "comment": null, "summary": "Temporal awareness underlies intelligent behavior in both animals and humans, guiding how actions are sequenced, paced, and adapted to changing goals and environments. Yet most robot learning algorithms remain blind to time. We introduce time-aware policy learning, a reinforcement learning framework that enables robots to explicitly perceive and reason with time as a first-class variable. The framework augments conventional reinforcement policies with two complementary temporal signals, the remaining time and a time ratio, which allow a single policy to modulate its behavior continuously from rapid and dynamic to cautious and precise execution. By jointly optimizing punctuality and stability, the robot learns to balance efficiency, robustness, resiliency, and punctuality without re-training or reward adjustment. Across diverse manipulation domains from long-horizon pick and place, to granular-media pouring, articulated-object handling, and multi-agent object delivery, the time-aware policy produces adaptive behaviors that outperform standard reinforcement learning baselines by up to 48% in efficiency, 8 times more robust in sim-to-real transfer, and 90% in acoustic quietness while maintaining near-perfect success rates. Explicit temporal reasoning further enables real-time human-in-the-loop control and multi-agent coordination, allowing robots to recover from disturbances, re-synchronize after delays, and align motion tempo with human intent. By treating time not as a constraint but as a controllable dimension of behavior, time-aware policy learning provides a unified foundation for efficient, robust, resilient, and human-aligned robot autonomy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65f6\u95f4\u611f\u77e5\u7b56\u7565\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u65f6\u95f4\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9996\u8981\u53d8\u91cf\uff0c\u901a\u8fc7\u5269\u4f59\u65f6\u95f4\u548c\u65f6\u95f4\u6bd4\u7387\u4e24\u4e2a\u65f6\u95f4\u4fe1\u53f7\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u6839\u636e\u65f6\u95f4\u8c03\u6574\u884c\u4e3a\uff0c\u5728\u6548\u7387\u548c\u7cbe\u786e\u6027\u4e4b\u95f4\u5b9e\u73b0\u5e73\u8861\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u673a\u5668\u4eba\u5b66\u4e60\u7b97\u6cd5\u7f3a\u4e4f\u65f6\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u65e0\u6cd5\u6839\u636e\u65f6\u95f4\u53d8\u5316\u8c03\u6574\u884c\u4e3a\u3002\u672c\u6587\u65e8\u5728\u8ba9\u673a\u5668\u4eba\u80fd\u591f\u660e\u786e\u611f\u77e5\u548c\u63a8\u7406\u65f6\u95f4\uff0c\u5b9e\u73b0\u4ece\u5feb\u901f\u52a8\u6001\u5230\u8c28\u614e\u7cbe\u786e\u7684\u8fde\u7eed\u884c\u4e3a\u8c03\u8282\u3002", "method": "\u63d0\u51fa\u65f6\u95f4\u611f\u77e5\u7b56\u7565\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u57fa\u7840\u4e0a\u589e\u52a0\u5269\u4f59\u65f6\u95f4\u548c\u65f6\u95f4\u6bd4\u7387\u4e24\u4e2a\u65f6\u95f4\u4fe1\u53f7\uff0c\u8054\u5408\u4f18\u5316\u51c6\u65f6\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4f7f\u5355\u4e00\u7b56\u7565\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u65f6\u95f4\u8981\u6c42\u3002", "result": "\u5728\u591a\u79cd\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0c\u65f6\u95f4\u611f\u77e5\u7b56\u7565\u76f8\u6bd4\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6548\u7387\u63d0\u534748%\uff0csim-to-real\u8fc1\u79fb\u9c81\u68d2\u6027\u63d0\u9ad88\u500d\uff0c\u58f0\u5b66\u5b89\u9759\u5ea6\u63d0\u534790%\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u901a\u8fc7\u5c06\u65f6\u95f4\u89c6\u4e3a\u53ef\u63a7\u7684\u884c\u4e3a\u7ef4\u5ea6\u800c\u975e\u7ea6\u675f\uff0c\u65f6\u95f4\u611f\u77e5\u7b56\u7565\u5b66\u4e60\u4e3a\u9ad8\u6548\u3001\u9c81\u68d2\u3001\u6709\u5f39\u6027\u548c\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u673a\u5668\u4eba\u81ea\u4e3b\u6027\u63d0\u4f9b\u4e86\u7edf\u4e00\u57fa\u7840\u3002"}}
{"id": "2511.07887", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07887", "abs": "https://arxiv.org/abs/2511.07887", "authors": ["Yinglei Zhu", "Xuguang Dong", "Qiyao Wang", "Qi Shao", "Fugui Xie", "Xinjun Liu", "Huichan Zhao"], "title": "EquiMus: Energy-Equivalent Dynamic Modeling and Simulation of Musculoskeletal Robots Driven by Linear Elastic Actuators", "comment": null, "summary": "Dynamic modeling and control are critical for unleashing soft robots' potential, yet remain challenging due to their complex constitutive behaviors and real-world operating conditions. Bio-inspired musculoskeletal robots, which integrate rigid skeletons with soft actuators, combine high load-bearing capacity with inherent flexibility. Although actuation dynamics have been studied through experimental methods and surrogate models, accurate and effective modeling and simulation remain a significant challenge, especially for large-scale hybrid rigid--soft robots with continuously distributed mass, kinematic loops, and diverse motion modes. To address these challenges, we propose EquiMus, an energy-equivalent dynamic modeling framework and MuJoCo-based simulation for musculoskeletal rigid--soft hybrid robots with linear elastic actuators. The equivalence and effectiveness of the proposed approach are validated and examined through both simulations and real-world experiments on a bionic robotic leg. EquiMus further demonstrates its utility for downstream tasks, including controller design and learning-based control strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86EquiMus\u6846\u67b6\uff0c\u7528\u4e8e\u808c\u8089\u9aa8\u9abc\u521a\u67d4\u6df7\u5408\u673a\u5668\u4eba\u7684\u52a8\u6001\u5efa\u6a21\u548c\u4eff\u771f\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6df7\u5408\u673a\u5668\u4eba\u5efa\u6a21\u7684\u6311\u6218\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u52a8\u6001\u5efa\u6a21\u548c\u63a7\u5236\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5177\u6709\u8fde\u7eed\u5206\u5e03\u8d28\u91cf\u3001\u8fd0\u52a8\u5b66\u73af\u8def\u548c\u591a\u6837\u5316\u8fd0\u52a8\u6a21\u5f0f\u7684\u5927\u89c4\u6a21\u521a\u67d4\u6df7\u5408\u673a\u5668\u4eba\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u80fd\u91cf\u7b49\u6548\u7684\u52a8\u6001\u5efa\u6a21\u6846\u67b6\u548cMuJoCo\u4eff\u771f\u5e73\u53f0\uff0c\u9488\u5bf9\u5177\u6709\u7ebf\u6027\u5f39\u6027\u9a71\u52a8\u5668\u7684\u808c\u8089\u9aa8\u9abc\u521a\u67d4\u6df7\u5408\u673a\u5668\u4eba\u3002", "result": "\u901a\u8fc7\u4eff\u751f\u673a\u5668\u4eba\u817f\u7684\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u7b49\u6548\u6027\u548c\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u63a7\u5236\u5668\u8bbe\u8ba1\u548c\u5b66\u4e60\u63a7\u5236\u7b56\u7565\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "EquiMus\u6846\u67b6\u4e3a\u89e3\u51b3\u808c\u8089\u9aa8\u9abc\u521a\u67d4\u6df7\u5408\u673a\u5668\u4eba\u7684\u7cbe\u786e\u5efa\u6a21\u548c\u4eff\u771f\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.08001", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.08001", "abs": "https://arxiv.org/abs/2511.08001", "authors": ["Avishav Engle", "Andrey Zhitnikov", "Oren Salzman", "Omer Ben-Porat", "Kiril Solovey"], "title": "Effective Game-Theoretic Motion Planning via Nested Search", "comment": null, "summary": "To facilitate effective, safe deployment in the real world, individual robots must reason about interactions with other agents, which often occur without explicit communication. Recent work has identified game theory, particularly the concept of Nash Equilibrium (NE), as a key enabler for behavior-aware decision-making. Yet, existing work falls short of fully unleashing the power of game-theoretic reasoning. Specifically, popular optimization-based methods require simplified robot dynamics and tend to get trapped in local minima due to convexification. Other works that rely on payoff matrices suffer from poor scalability due to the explicit enumeration of all possible trajectories. To bridge this gap, we introduce Game-Theoretic Nested Search (GTNS), a novel, scalable, and provably correct approach for computing NEs in general dynamical systems. GTNS efficiently searches the action space of all agents involved, while discarding trajectories that violate the NE constraint (no unilateral deviation) through an inner search over a lower-dimensional space. Our algorithm enables explicit selection among equilibria by utilizing a user-specified global objective, thereby capturing a rich set of realistic interactions. We demonstrate the approach on a variety of autonomous driving and racing scenarios where we achieve solutions in mere seconds on commodity hardware.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGTNS\uff08Game-Theoretic Nested Search\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4e00\u822c\u52a8\u529b\u7cfb\u7edf\u4e2d\u8ba1\u7b97\u7eb3\u4ec0\u5747\u8861\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u4ea4\u4e92\u51b3\u7b56\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u673a\u5668\u4eba\u884c\u4e3a\u611f\u77e5\u51b3\u7b56\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff1a\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u7b80\u5316\u673a\u5668\u4eba\u52a8\u529b\u5b66\u4e14\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u57fa\u4e8e\u6536\u76ca\u77e9\u9635\u7684\u65b9\u6cd5\u56e0\u663e\u5f0f\u679a\u4e3e\u6240\u6709\u53ef\u80fd\u8f68\u8ff9\u800c\u6269\u5c55\u6027\u5dee\u3002", "method": "GTNS\u901a\u8fc7\u5728\u6240\u6709\u667a\u80fd\u4f53\u7684\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9ad8\u6548\u641c\u7d22\uff0c\u540c\u65f6\u901a\u8fc7\u5185\u90e8\u641c\u7d22\u5728\u4f4e\u7ef4\u7a7a\u95f4\u4e2d\u4e22\u5f03\u8fdd\u53cd\u7eb3\u4ec0\u5747\u8861\u7ea6\u675f\uff08\u65e0\u5355\u8fb9\u504f\u5dee\uff09\u7684\u8f68\u8ff9\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u548c\u8d5b\u8f66\u573a\u666f\u4e2d\u5b9e\u73b0\uff0c\u5728\u666e\u901a\u786c\u4ef6\u4e0a\u4ec5\u9700\u51e0\u79d2\u5373\u53ef\u83b7\u5f97\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "GTNS\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u7528\u6237\u6307\u5b9a\u7684\u5168\u5c40\u76ee\u6807\u5728\u5747\u8861\u4e2d\u8fdb\u884c\u663e\u5f0f\u9009\u62e9\uff0c\u6355\u6349\u4e30\u5bcc\u7684\u73b0\u5b9e\u4ea4\u4e92\u3002"}}
{"id": "2511.08005", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.08005", "abs": "https://arxiv.org/abs/2511.08005", "authors": ["Huacen Wang", "Hongqiang Wang"], "title": "A Two-Layer Electrostatic Film Actuator with High Actuation Stress and Integrated Brake", "comment": null, "summary": "Robotic systems driven by conventional motors often suffer from challenges such as large mass, complex control algorithms, and the need for additional braking mechanisms, which limit their applications in lightweight and compact robotic platforms. Electrostatic film actuators offer several advantages, including thinness, flexibility, lightweight construction, and high open-loop positioning accuracy. However, the actuation stress exhibited by conventional actuators in air still needs improvement, particularly for the widely used three-phase electrode design. To enhance the output performance of actuators, this paper presents a two-layer electrostatic film actuator with an integrated brake. By alternately distributing electrodes on both the top and bottom layers, a smaller effective electrode pitch is achieved under the same fabrication constraints, resulting in an actuation stress of approximately 241~N/m$^2$, representing a 90.5\\% improvement over previous three-phase actuators operating in air. Furthermore, its integrated electrostatic adhesion mechanism enables load retention under braking mode. Several demonstrations, including a tug-of-war between a conventional single-layer actuator and the proposed two-layer actuator, a payload operation, a one-degree-of-freedom robotic arm, and a dual-mode gripper, were conducted to validate the actuator's advantageous capabilities in both actuation and braking modes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u96c6\u6210\u5236\u52a8\u5668\u7684\u53cc\u5c42\u9759\u7535\u8584\u819c\u9a71\u52a8\u5668\uff0c\u901a\u8fc7\u5728\u9876\u5c42\u548c\u5e95\u5c42\u4ea4\u66ff\u5206\u5e03\u7535\u6781\uff0c\u5728\u76f8\u540c\u5236\u9020\u7ea6\u675f\u4e0b\u5b9e\u73b0\u66f4\u5c0f\u7684\u6709\u6548\u7535\u6781\u95f4\u8ddd\uff0c\u4f7f\u9a71\u52a8\u5e94\u529b\u8fbe\u5230\u7ea6241 N/m\u00b2\uff0c\u6bd4\u4e4b\u524d\u7684\u4e09\u76f8\u9a71\u52a8\u5668\u63d0\u9ad8\u4e8690.5%\u3002\u8be5\u9a71\u52a8\u5668\u8fd8\u96c6\u6210\u4e86\u9759\u7535\u7c98\u9644\u673a\u5236\uff0c\u53ef\u5728\u5236\u52a8\u6a21\u5f0f\u4e0b\u4fdd\u6301\u8d1f\u8f7d\u3002", "motivation": "\u4f20\u7edf\u7535\u673a\u9a71\u52a8\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u5b58\u5728\u8d28\u91cf\u5927\u3001\u63a7\u5236\u7b97\u6cd5\u590d\u6742\u3001\u9700\u8981\u989d\u5916\u5236\u52a8\u673a\u5236\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u8f7b\u91cf\u7d27\u51d1\u673a\u5668\u4eba\u5e73\u53f0\u7684\u5e94\u7528\u3002\u9759\u7535\u8584\u819c\u9a71\u52a8\u5668\u867d\u7136\u5177\u6709\u8584\u3001\u67d4\u3001\u8f7b\u3001\u9ad8\u5f00\u73af\u5b9a\u4f4d\u7cbe\u5ea6\u7b49\u4f18\u52bf\uff0c\u4f46\u4f20\u7edf\u9a71\u52a8\u5668\u5728\u7a7a\u6c14\u4e2d\u7684\u9a71\u52a8\u5e94\u529b\u4ecd\u9700\u6539\u8fdb\u3002", "method": "\u8bbe\u8ba1\u53cc\u5c42\u9759\u7535\u8584\u819c\u9a71\u52a8\u5668\uff0c\u5728\u9876\u5c42\u548c\u5e95\u5c42\u4ea4\u66ff\u5206\u5e03\u7535\u6781\uff0c\u5b9e\u73b0\u66f4\u5c0f\u7684\u6709\u6548\u7535\u6781\u95f4\u8ddd\u3002\u540c\u65f6\u96c6\u6210\u9759\u7535\u7c98\u9644\u673a\u5236\u4f5c\u4e3a\u5236\u52a8\u529f\u80fd\u3002", "result": "\u9a71\u52a8\u5e94\u529b\u8fbe\u5230\u7ea6241 N/m\u00b2\uff0c\u6bd4\u4e4b\u524d\u7684\u4e09\u76f8\u9a71\u52a8\u5668\u63d0\u9ad8\u4e8690.5%\u3002\u901a\u8fc7\u62d4\u6cb3\u5b9e\u9a8c\u3001\u8d1f\u8f7d\u64cd\u4f5c\u3001\u5355\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u548c\u53cc\u6a21\u5f0f\u5939\u6301\u5668\u7b49\u6f14\u793a\u9a8c\u8bc1\u4e86\u9a71\u52a8\u5668\u5728\u9a71\u52a8\u548c\u5236\u52a8\u6a21\u5f0f\u4e0b\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u53cc\u5c42\u9759\u7535\u8584\u819c\u9a71\u52a8\u5668\u5728\u9a71\u52a8\u6027\u80fd\u548c\u5236\u52a8\u80fd\u529b\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u8f7b\u91cf\u7d27\u51d1\u673a\u5668\u4eba\u5e73\u53f0\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08377", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.08377", "abs": "https://arxiv.org/abs/2511.08377", "authors": ["Michael Bowman", "Xiaoli Zhang"], "title": "Human Motion Intent Inferencing in Teleoperation Through a SINDy Paradigm", "comment": "Open source software and video examples here: https://github.com/namwob44/Psychic", "summary": "Intent inferencing in teleoperation has been instrumental in aligning operator goals and coordinating actions with robotic partners. However, current intent inference methods often ignore subtle motion that can be strong indicators for a sudden change in intent. Specifically, we aim to tackle 1) if we can detect sudden jumps in operator trajectories, 2) how we appropriately use these sudden jump motions to infer an operator's goal state, and 3) how to incorporate these discontinuous and continuous dynamics to infer operator motion. Our framework, called Psychic, models these small indicative motions through a jump-drift-diffusion stochastic differential equation to cover discontinuous and continuous dynamics. Kramers-Moyal (KM) coefficients allow us to detect jumps with a trajectory which we pair with a statistical outlier detection algorithm to nominate goal transitions. Through identifying jumps, we can perform early detection of existing goals and discover undefined goals in unstructured scenarios. Our framework then applies a Sparse Identification of Nonlinear Dynamics (SINDy) model using KM coefficients with the goal transitions as a control input to infer an operator's motion behavior in unstructured scenarios. We demonstrate Psychic can produce probabilistic reachability sets and compare our strategy to a negative log-likelihood model fit. We perform a retrospective study on 600 operator trajectories in a hands-free teleoperation task to evaluate the efficacy of our opensource package, Psychic, in both offline and online learning.", "AI": {"tldr": "Psychic\u6846\u67b6\u901a\u8fc7\u8df3\u8dc3-\u6f02\u79fb-\u6269\u6563\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u5efa\u6a21\u64cd\u4f5c\u8005\u8fd0\u52a8\u4e2d\u7684\u7ec6\u5fae\u8df3\u8dc3\u52a8\u4f5c\uff0c\u7ed3\u5408Kramers-Moyal\u7cfb\u6570\u548c\u7edf\u8ba1\u5f02\u5e38\u68c0\u6d4b\u6765\u8bc6\u522b\u76ee\u6807\u8f6c\u6362\uff0c\u4f7f\u7528SINDy\u6a21\u578b\u63a8\u65ad\u64cd\u4f5c\u8005\u5728\u975e\u7ed3\u6784\u5316\u573a\u666f\u4e2d\u7684\u8fd0\u52a8\u884c\u4e3a\u3002", "motivation": "\u5f53\u524d\u610f\u56fe\u63a8\u65ad\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u7ec6\u5fae\u8fd0\u52a8\u53d8\u5316\uff0c\u800c\u8fd9\u4e9b\u53d8\u5316\u53ef\u80fd\u662f\u610f\u56fe\u7a81\u7136\u6539\u53d8\u7684\u5f3a\u6709\u529b\u6307\u6807\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\uff1a1\uff09\u68c0\u6d4b\u64cd\u4f5c\u8005\u8f68\u8ff9\u4e2d\u7684\u7a81\u7136\u8df3\u8dc3\uff1b2\uff09\u5229\u7528\u8fd9\u4e9b\u8df3\u8dc3\u52a8\u4f5c\u63a8\u65ad\u64cd\u4f5c\u8005\u7684\u76ee\u6807\u72b6\u6001\uff1b3\uff09\u7ed3\u5408\u4e0d\u8fde\u7eed\u548c\u8fde\u7eed\u52a8\u6001\u63a8\u65ad\u64cd\u4f5c\u8005\u8fd0\u52a8\u3002", "method": "\u63d0\u51faPsychic\u6846\u67b6\uff0c\u4f7f\u7528\u8df3\u8dc3-\u6f02\u79fb-\u6269\u6563\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u5efa\u6a21\u4e0d\u8fde\u7eed\u548c\u8fde\u7eed\u52a8\u6001\uff0c\u901a\u8fc7Kramers-Moyal\u7cfb\u6570\u68c0\u6d4b\u8df3\u8dc3\uff0c\u7ed3\u5408\u7edf\u8ba1\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u63d0\u540d\u76ee\u6807\u8f6c\u6362\uff0c\u5e94\u7528SINDy\u6a21\u578b\u63a8\u65ad\u64cd\u4f5c\u8005\u8fd0\u52a8\u884c\u4e3a\u3002", "result": "Psychic\u80fd\u591f\u751f\u6210\u6982\u7387\u53ef\u8fbe\u96c6\uff0c\u5728600\u4e2a\u64cd\u4f5c\u8005\u8f68\u8ff9\u7684\u56de\u987e\u6027\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u80fd\u591f\u65e9\u671f\u68c0\u6d4b\u73b0\u6709\u76ee\u6807\u5e76\u5728\u975e\u7ed3\u6784\u5316\u573a\u666f\u4e2d\u53d1\u73b0\u672a\u5b9a\u4e49\u76ee\u6807\u3002", "conclusion": "Psychic\u6846\u67b6\u901a\u8fc7\u5efa\u6a21\u7ec6\u5fae\u8df3\u8dc3\u52a8\u4f5c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9065\u64cd\u4f5c\u4e2d\u610f\u56fe\u63a8\u65ad\u7684\u95ee\u9898\uff0c\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b66\u4e60\u4e2d\u5747\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\uff0c\u4e3a\u64cd\u4f5c\u8005\u8fd0\u52a8\u884c\u4e3a\u63a8\u65ad\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2511.08454", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.08454", "abs": "https://arxiv.org/abs/2511.08454", "authors": ["Tianyu Jia", "Xingchen Yang", "Ciaran McGeady", "Yifeng Li", "Jinzhi Lin", "Kit San Ho", "Feiyu Pan", "Linhong Ji", "Chong Li", "Dario Farina"], "title": "Intuitive control of supernumerary robotic limbs through a tactile-encoded neural interface", "comment": null, "summary": "Brain-computer interfaces (BCIs) promise to extend human movement capabilities by enabling direct neural control of supernumerary effectors, yet integrating augmented commands with multiple degrees of freedom without disrupting natural movement remains a key challenge. Here, we propose a tactile-encoded BCI that leverages sensory afferents through a novel tactile-evoked P300 paradigm, allowing intuitive and reliable decoding of supernumerary motor intentions even when superimposed with voluntary actions. The interface was evaluated in a multi-day experiment comprising of a single motor recognition task to validate baseline BCI performance and a dual task paradigm to assess the potential influence between the BCI and natural human movement. The brain interface achieved real-time and reliable decoding of four supernumerary degrees of freedom, with significant performance improvements after only three days of training. Importantly, after training, performance did not differ significantly between the single- and dual-BCI task conditions, and natural movement remained unimpaired during concurrent supernumerary control. Lastly, the interface was deployed in a movement augmentation task, demonstrating its ability to command two supernumerary robotic arms for functional assistance during bimanual tasks. These results establish a new neural interface paradigm for movement augmentation through stimulation of sensory afferents, expanding motor degrees of freedom without impairing natural movement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89e6\u89c9\u7f16\u7801\u7684\u8111\u673a\u63a5\u53e3\uff0c\u901a\u8fc7\u89e6\u89c9\u8bf1\u53d1P300\u8303\u5f0f\u5b9e\u73b0\u8d85\u9650\u8fd0\u52a8\u610f\u56fe\u7684\u76f4\u89c2\u53ef\u9760\u89e3\u7801\uff0c\u53ef\u5728\u4e0d\u5e72\u6270\u81ea\u7136\u8fd0\u52a8\u7684\u60c5\u51b5\u4e0b\u6269\u5c55\u8fd0\u52a8\u81ea\u7531\u5ea6\u3002", "motivation": "\u89e3\u51b3\u8111\u673a\u63a5\u53e3\u5728\u6269\u5c55\u4eba\u7c7b\u8fd0\u52a8\u80fd\u529b\u65f6\u9762\u4e34\u7684\u6311\u6218\u2014\u2014\u5982\u4f55\u5728\u4e0d\u5e72\u6270\u81ea\u7136\u8fd0\u52a8\u7684\u60c5\u51b5\u4e0b\u6574\u5408\u5177\u6709\u591a\u4e2a\u81ea\u7531\u5ea6\u7684\u589e\u5f3a\u6307\u4ee4\u3002", "method": "\u91c7\u7528\u89e6\u89c9\u7f16\u7801\u7684\u8111\u673a\u63a5\u53e3\uff0c\u5229\u7528\u65b0\u578b\u89e6\u89c9\u8bf1\u53d1P300\u8303\u5f0f\uff0c\u901a\u8fc7\u523a\u6fc0\u611f\u89c9\u4f20\u5165\u795e\u7ecf\u6765\u89e3\u7801\u8d85\u9650\u8fd0\u52a8\u610f\u56fe\u3002\u5728\u591a\u65e5\u5b9e\u9a8c\u4e2d\u8bc4\u4f30\u5355\u4efb\u52a1\u548c\u53cc\u4efb\u52a1\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u73b0\u4e86\u56db\u4e2a\u8d85\u9650\u81ea\u7531\u5ea6\u7684\u5b9e\u65f6\u53ef\u9760\u89e3\u7801\uff0c\u4ec5\u4e09\u5929\u8bad\u7ec3\u540e\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002\u8bad\u7ec3\u540e\u5355\u53cc\u4efb\u52a1\u6027\u80fd\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u81ea\u7136\u8fd0\u52a8\u5728\u5e76\u53d1\u8d85\u9650\u63a7\u5236\u65f6\u4fdd\u6301\u4e0d\u53d7\u5f71\u54cd\u3002\u6210\u529f\u5e94\u7528\u4e8e\u53cc\u624b\u673a\u5668\u4eba\u81c2\u7684\u529f\u80fd\u8f85\u52a9\u4efb\u52a1\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u79cd\u901a\u8fc7\u523a\u6fc0\u611f\u89c9\u4f20\u5165\u795e\u7ecf\u5b9e\u73b0\u8fd0\u52a8\u589e\u5f3a\u7684\u65b0\u795e\u7ecf\u63a5\u53e3\u8303\u5f0f\uff0c\u53ef\u5728\u4e0d\u635f\u5bb3\u81ea\u7136\u8fd0\u52a8\u7684\u60c5\u51b5\u4e0b\u6269\u5c55\u8fd0\u52a8\u81ea\u7531\u5ea6\u3002"}}
{"id": "2511.08502", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.08502", "abs": "https://arxiv.org/abs/2511.08502", "authors": ["Ruya Karagulle", "Cristian-Ioan Vasile", "Necmiye Ozay"], "title": "Safe and Optimal Learning from Preferences via Weighted Temporal Logic with Applications in Robotics and Formula 1", "comment": "8 pages, 2 figures", "summary": "Autonomous systems increasingly rely on human feedback to align their behavior, expressed as pairwise comparisons, rankings, or demonstrations. While existing methods can adapt behaviors, they often fail to guarantee safety in safety-critical domains. We propose a safety-guaranteed, optimal, and efficient approach to solve the learning problem from preferences, rankings, or demonstrations using Weighted Signal Temporal Logic (WSTL). WSTL learning problems, when implemented naively, lead to multi-linear constraints in the weights to be learned. By introducing structural pruning and log-transform procedures, we reduce the problem size and recast the problem as a Mixed-Integer Linear Program while preserving safety guarantees. Experiments on robotic navigation and real-world Formula 1 data demonstrate that the method effectively captures nuanced preferences and models complex task objectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08WSTL\uff09\u7684\u5b89\u5168\u4fdd\u8bc1\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u504f\u597d\u3001\u6392\u540d\u6216\u6f14\u793a\u4e2d\u5b66\u4e60\uff0c\u901a\u8fc7\u7ed3\u6784\u526a\u679d\u548c\u5bf9\u6570\u53d8\u6362\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u786e\u4fdd\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u4e2d\u5f80\u5f80\u65e0\u6cd5\u4fdd\u8bc1\u5b89\u5168\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9002\u5e94\u884c\u4e3a\u53c8\u80fd\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u52a0\u6743\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08WSTL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u526a\u679d\u548c\u5bf9\u6570\u53d8\u6362\u5c06\u591a\u7ebf\u6027\u7ea6\u675f\u95ee\u9898\u8f6c\u5316\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u3002", "result": "\u5728\u673a\u5668\u4eba\u5bfc\u822a\u548c\u771f\u5b9e\u4e16\u754cF1\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u6349\u7ec6\u5fae\u504f\u597d\u5e76\u5efa\u6a21\u590d\u6742\u4efb\u52a1\u76ee\u6807\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u4fdd\u8bc1\u3001\u6700\u4f18\u4e14\u9ad8\u6548\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4ece\u504f\u597d\u3001\u6392\u540d\u6216\u6f14\u793a\u4e2d\u5b66\u4e60\u7684\u5b89\u5168\u5173\u952e\u5e94\u7528\u3002"}}
{"id": "2511.08583", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08583", "abs": "https://arxiv.org/abs/2511.08583", "authors": ["Rong Xue", "Jiageng Mao", "Mingtong Zhang", "Yue Wang"], "title": "SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment", "comment": null, "summary": "Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the ground-truth actions corresponding to the current visual observation, leading to accumulated error as the reflow process repeats and unstable task execution. We present Selective Flow Alignment (SeFA), an efficient and accurate visuomotor policy learning framework. SeFA resolves this challenge by a selective flow alignment strategy, which leverages expert demonstrations to selectively correct generated actions and restore consistency with observations, while preserving multimodality. This design introduces a consistency correction mechanism that ensures generated actions remain observation-aligned without sacrificing the efficiency of one-step flow inference. Extensive experiments across both simulated and real-world manipulation tasks show that SeFA Policy surpasses state-of-the-art diffusion-based and flow-based policies, achieving superior accuracy and robustness while reducing inference latency by over 98%. By unifying rectified flow efficiency with observation-consistent action generation, SeFA provides a scalable and dependable solution for real-time visuomotor policy learning. Code is available on https://github.com/RongXueZoe/SeFA.", "AI": {"tldr": "SeFA\u63d0\u51fa\u4e86\u4e00\u79cd\u9009\u62e9\u6027\u6d41\u5bf9\u9f50\u7b56\u7565\uff0c\u901a\u8fc7\u4e13\u5bb6\u6f14\u793a\u9009\u62e9\u6027\u6821\u6b63\u751f\u6210\u7684\u52a8\u4f5c\u4ee5\u4fdd\u6301\u4e0e\u89c2\u5bdf\u7684\u4e00\u81f4\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6574\u6d41\u6d41\u65b9\u6cd5\u4e2d\u52a8\u4f5c\u504f\u79bb\u5730\u9762\u771f\u5b9e\u503c\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6574\u6d41\u6d41\u65b9\u6cd5\u5728\u8fed\u4ee3\u84b8\u998f\u540e\uff0c\u751f\u6210\u7684\u52a8\u4f5c\u53ef\u80fd\u504f\u79bb\u5f53\u524d\u89c6\u89c9\u89c2\u5bdf\u5bf9\u5e94\u7684\u5730\u9762\u771f\u5b9e\u52a8\u4f5c\uff0c\u5bfc\u81f4\u7d2f\u79ef\u8bef\u5dee\u548c\u4e0d\u7a33\u5b9a\u7684\u4efb\u52a1\u6267\u884c\u3002", "method": "\u91c7\u7528\u9009\u62e9\u6027\u6d41\u5bf9\u9f50\u7b56\u7565\uff0c\u5229\u7528\u4e13\u5bb6\u6f14\u793a\u9009\u62e9\u6027\u6821\u6b63\u751f\u6210\u52a8\u4f5c\u5e76\u6062\u590d\u4e0e\u89c2\u5bdf\u7684\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u591a\u6a21\u6001\u6027\uff0c\u5f15\u5165\u4e00\u81f4\u6027\u6821\u6b63\u673a\u5236\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u64cd\u4f5c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSeFA\u7b56\u7565\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u6269\u6563\u548c\u6d41\u7684\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5c06\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u4e8698%\u4ee5\u4e0a\u3002", "conclusion": "SeFA\u901a\u8fc7\u7edf\u4e00\u6574\u6d41\u6d41\u6548\u7387\u4e0e\u89c2\u5bdf\u4e00\u81f4\u7684\u52a8\u4f5c\u751f\u6210\uff0c\u4e3a\u5b9e\u65f6\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07928", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07928", "abs": "https://arxiv.org/abs/2511.07928", "authors": ["Selim Ahmet Iz", "Mustafa Unel"], "title": "An Image-Based Path Planning Algorithm Using a UAV Equipped with Stereo Vision", "comment": null, "summary": "This paper presents a novel image-based path planning algorithm that was developed using computer vision techniques, as well as its comparative analysis with well-known deterministic and probabilistic algorithms, namely A* and Probabilistic Road Map algorithm (PRM). The terrain depth has a significant impact on the calculated path safety. The craters and hills on the surface cannot be distinguished in a two-dimensional image. The proposed method uses a disparity map of the terrain that is generated by using a UAV. Several computer vision techniques, including edge, line and corner detection methods, as well as the stereo depth reconstruction technique, are applied to the captured images and the found disparity map is used to define candidate way-points of the trajectory. The initial and desired points are detected automatically using ArUco marker pose estimation and circle detection techniques. After presenting the mathematical model and vision techniques, the developed algorithm is compared with well-known algorithms on different virtual scenes created in the V-REP simulation program and a physical setup created in a laboratory environment. Results are promising and demonstrate effectiveness of the proposed algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u65b0\u578b\u56fe\u50cf\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\uff0c\u5e76\u4e0eA*\u548cPRM\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u65e0\u4eba\u673a\u751f\u6210\u7684\u5730\u5f62\u89c6\u5dee\u56fe\uff0c\u901a\u8fc7\u8fb9\u7f18\u3001\u7ebf\u6761\u3001\u89d2\u70b9\u68c0\u6d4b\u548c\u7acb\u4f53\u6df1\u5ea6\u91cd\u5efa\u6280\u672f\u5b9a\u4e49\u8f68\u8ff9\u5019\u9009\u8def\u5f84\u70b9\u3002", "motivation": "\u4f20\u7edf\u4e8c\u7ef4\u56fe\u50cf\u65e0\u6cd5\u533a\u5206\u5730\u5f62\u4e2d\u7684\u9668\u77f3\u5751\u548c\u5c71\u4e18\u7b49\u6df1\u5ea6\u53d8\u5316\uff0c\u5730\u5f62\u6df1\u5ea6\u5bf9\u8def\u5f84\u5b89\u5168\u6027\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8003\u8651\u4e09\u7ef4\u5730\u5f62\u4fe1\u606f\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u65e0\u4eba\u673a\u751f\u6210\u5730\u5f62\u89c6\u5dee\u56fe\uff0c\u5e94\u7528\u8fb9\u7f18\u3001\u7ebf\u6761\u3001\u89d2\u70b9\u68c0\u6d4b\u548c\u7acb\u4f53\u6df1\u5ea6\u91cd\u5efa\u7b49\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\uff0c\u7ed3\u5408ArUco\u6807\u8bb0\u59ff\u6001\u4f30\u8ba1\u548c\u5706\u5f62\u68c0\u6d4b\u81ea\u52a8\u8bc6\u522b\u8d77\u70b9\u548c\u7ec8\u70b9\uff0c\u5728V-REP\u4eff\u771f\u73af\u5883\u548c\u5b9e\u9a8c\u5ba4\u7269\u7406\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u4e0d\u540c\u865a\u62df\u573a\u666f\u548c\u7269\u7406\u73af\u5883\u4e2d\u7684\u6d4b\u8bd5\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u8868\u73b0\u826f\u597d\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u56fe\u50cf\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4e09\u7ef4\u5730\u5f62\u4fe1\u606f\uff0c\u5728\u8def\u5f84\u89c4\u5212\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u5730\u5f62\u73af\u5883\u4e0b\u7684\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
