<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.RO](#cs.RO) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [An Image-Based Path Planning Algorithm Using a UAV Equipped with Stereo Vision](https://arxiv.org/abs/2511.07928)
*Selim Ahmet Iz,Mustafa Unel*

Main category: cs.CV

TL;DR: 本文提出了一种基于计算机视觉的新型图像路径规划算法，并与A*和PRM算法进行了比较分析。该方法使用无人机生成的地形视差图，通过边缘、线条、角点检测和立体深度重建技术定义轨迹候选路径点。


<details>
  <summary>Details</summary>
Motivation: 传统二维图像无法区分地形中的陨石坑和山丘等深度变化，地形深度对路径安全性有重要影响，因此需要开发能够考虑三维地形信息的路径规划方法。

Method: 使用无人机生成地形视差图，应用边缘、线条、角点检测和立体深度重建等计算机视觉技术，结合ArUco标记姿态估计和圆形检测自动识别起点和终点，在V-REP仿真环境和实验室物理设置中进行验证。

Result: 在不同虚拟场景和物理环境中的测试结果表明，所提出的算法表现良好，证明了其有效性。

Conclusion: 基于计算机视觉的图像路径规划算法能够有效处理三维地形信息，在路径规划中表现出良好的性能，为复杂地形环境下的自主导航提供了可行方案。

Abstract: This paper presents a novel image-based path planning algorithm that was developed using computer vision techniques, as well as its comparative analysis with well-known deterministic and probabilistic algorithms, namely A* and Probabilistic Road Map algorithm (PRM). The terrain depth has a significant impact on the calculated path safety. The craters and hills on the surface cannot be distinguished in a two-dimensional image. The proposed method uses a disparity map of the terrain that is generated by using a UAV. Several computer vision techniques, including edge, line and corner detection methods, as well as the stereo depth reconstruction technique, are applied to the captured images and the found disparity map is used to define candidate way-points of the trajectory. The initial and desired points are detected automatically using ArUco marker pose estimation and circle detection techniques. After presenting the mathematical model and vision techniques, the developed algorithm is compared with well-known algorithms on different virtual scenes created in the V-REP simulation program and a physical setup created in a laboratory environment. Results are promising and demonstrate effectiveness of the proposed algorithm.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [2] [Time-Aware Policy Learning for Adaptive and Punctual Robot Control](https://arxiv.org/abs/2511.07654)
*Yinsen Jia,Boyuan Chen*

Main category: cs.RO

TL;DR: 本文提出了一种时间感知策略学习框架，将时间作为强化学习中的首要变量，通过剩余时间和时间比率两个时间信号，使机器人能够根据时间调整行为，在效率和精确性之间实现平衡。


<details>
  <summary>Details</summary>
Motivation: 当前大多数机器人学习算法缺乏时间感知能力，无法根据时间变化调整行为。本文旨在让机器人能够明确感知和推理时间，实现从快速动态到谨慎精确的连续行为调节。

Method: 提出时间感知策略学习框架，在传统强化学习策略基础上增加剩余时间和时间比率两个时间信号，联合优化准时性和稳定性，使单一策略能够适应不同时间要求。

Result: 在多种操作任务中，时间感知策略相比标准强化学习方法效率提升48%，sim-to-real迁移鲁棒性提高8倍，声学安静度提升90%，同时保持接近完美的成功率。

Conclusion: 通过将时间视为可控的行为维度而非约束，时间感知策略学习为高效、鲁棒、有弹性和与人类对齐的机器人自主性提供了统一基础。

Abstract: Temporal awareness underlies intelligent behavior in both animals and humans, guiding how actions are sequenced, paced, and adapted to changing goals and environments. Yet most robot learning algorithms remain blind to time. We introduce time-aware policy learning, a reinforcement learning framework that enables robots to explicitly perceive and reason with time as a first-class variable. The framework augments conventional reinforcement policies with two complementary temporal signals, the remaining time and a time ratio, which allow a single policy to modulate its behavior continuously from rapid and dynamic to cautious and precise execution. By jointly optimizing punctuality and stability, the robot learns to balance efficiency, robustness, resiliency, and punctuality without re-training or reward adjustment. Across diverse manipulation domains from long-horizon pick and place, to granular-media pouring, articulated-object handling, and multi-agent object delivery, the time-aware policy produces adaptive behaviors that outperform standard reinforcement learning baselines by up to 48% in efficiency, 8 times more robust in sim-to-real transfer, and 90% in acoustic quietness while maintaining near-perfect success rates. Explicit temporal reasoning further enables real-time human-in-the-loop control and multi-agent coordination, allowing robots to recover from disturbances, re-synchronize after delays, and align motion tempo with human intent. By treating time not as a constraint but as a controllable dimension of behavior, time-aware policy learning provides a unified foundation for efficient, robust, resilient, and human-aligned robot autonomy.

</details>


### [3] [EquiMus: Energy-Equivalent Dynamic Modeling and Simulation of Musculoskeletal Robots Driven by Linear Elastic Actuators](https://arxiv.org/abs/2511.07887)
*Yinglei Zhu,Xuguang Dong,Qiyao Wang,Qi Shao,Fugui Xie,Xinjun Liu,Huichan Zhao*

Main category: cs.RO

TL;DR: 提出了EquiMus框架，用于肌肉骨骼刚柔混合机器人的动态建模和仿真，解决了大规模混合机器人建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 软体机器人动态建模和控制面临挑战，特别是具有连续分布质量、运动学环路和多样化运动模式的大规模刚柔混合机器人。

Method: 开发了基于能量等效的动态建模框架和MuJoCo仿真平台，针对具有线性弹性驱动器的肌肉骨骼刚柔混合机器人。

Result: 通过仿生机器人腿的仿真和真实实验验证了方法的等效性和有效性，并展示了在控制器设计和学习控制策略中的应用价值。

Conclusion: EquiMus框架为解决肌肉骨骼刚柔混合机器人的精确建模和仿真提供了有效解决方案，具有实际应用潜力。

Abstract: Dynamic modeling and control are critical for unleashing soft robots' potential, yet remain challenging due to their complex constitutive behaviors and real-world operating conditions. Bio-inspired musculoskeletal robots, which integrate rigid skeletons with soft actuators, combine high load-bearing capacity with inherent flexibility. Although actuation dynamics have been studied through experimental methods and surrogate models, accurate and effective modeling and simulation remain a significant challenge, especially for large-scale hybrid rigid--soft robots with continuously distributed mass, kinematic loops, and diverse motion modes. To address these challenges, we propose EquiMus, an energy-equivalent dynamic modeling framework and MuJoCo-based simulation for musculoskeletal rigid--soft hybrid robots with linear elastic actuators. The equivalence and effectiveness of the proposed approach are validated and examined through both simulations and real-world experiments on a bionic robotic leg. EquiMus further demonstrates its utility for downstream tasks, including controller design and learning-based control strategies.

</details>


### [4] [Effective Game-Theoretic Motion Planning via Nested Search](https://arxiv.org/abs/2511.08001)
*Avishav Engle,Andrey Zhitnikov,Oren Salzman,Omer Ben-Porat,Kiril Solovey*

Main category: cs.RO

TL;DR: 本文提出了一种名为GTNS（Game-Theoretic Nested Search）的新方法，用于在一般动力系统中计算纳什均衡，解决了现有方法在机器人交互决策中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于博弈论的机器人行为感知决策方法存在不足：优化方法需要简化机器人动力学且易陷入局部最优，基于收益矩阵的方法因显式枚举所有可能轨迹而扩展性差。

Method: GTNS通过在所有智能体的动作空间中进行高效搜索，同时通过内部搜索在低维空间中丢弃违反纳什均衡约束（无单边偏差）的轨迹。

Result: 该方法在自动驾驶和赛车场景中实现，在普通硬件上仅需几秒即可获得解决方案。

Conclusion: GTNS是一种可扩展且可证明正确的方法，能够通过用户指定的全局目标在均衡中进行显式选择，捕捉丰富的现实交互。

Abstract: To facilitate effective, safe deployment in the real world, individual robots must reason about interactions with other agents, which often occur without explicit communication. Recent work has identified game theory, particularly the concept of Nash Equilibrium (NE), as a key enabler for behavior-aware decision-making. Yet, existing work falls short of fully unleashing the power of game-theoretic reasoning. Specifically, popular optimization-based methods require simplified robot dynamics and tend to get trapped in local minima due to convexification. Other works that rely on payoff matrices suffer from poor scalability due to the explicit enumeration of all possible trajectories. To bridge this gap, we introduce Game-Theoretic Nested Search (GTNS), a novel, scalable, and provably correct approach for computing NEs in general dynamical systems. GTNS efficiently searches the action space of all agents involved, while discarding trajectories that violate the NE constraint (no unilateral deviation) through an inner search over a lower-dimensional space. Our algorithm enables explicit selection among equilibria by utilizing a user-specified global objective, thereby capturing a rich set of realistic interactions. We demonstrate the approach on a variety of autonomous driving and racing scenarios where we achieve solutions in mere seconds on commodity hardware.

</details>


### [5] [A Two-Layer Electrostatic Film Actuator with High Actuation Stress and Integrated Brake](https://arxiv.org/abs/2511.08005)
*Huacen Wang,Hongqiang Wang*

Main category: cs.RO

TL;DR: 本文提出了一种带有集成制动器的双层静电薄膜驱动器，通过在顶层和底层交替分布电极，在相同制造约束下实现更小的有效电极间距，使驱动应力达到约241 N/m²，比之前的三相驱动器提高了90.5%。该驱动器还集成了静电粘附机制，可在制动模式下保持负载。


<details>
  <summary>Details</summary>
Motivation: 传统电机驱动的机器人系统存在质量大、控制算法复杂、需要额外制动机制等问题，限制了其在轻量紧凑机器人平台的应用。静电薄膜驱动器虽然具有薄、柔、轻、高开环定位精度等优势，但传统驱动器在空气中的驱动应力仍需改进。

Method: 设计双层静电薄膜驱动器，在顶层和底层交替分布电极，实现更小的有效电极间距。同时集成静电粘附机制作为制动功能。

Result: 驱动应力达到约241 N/m²，比之前的三相驱动器提高了90.5%。通过拔河实验、负载操作、单自由度机械臂和双模式夹持器等演示验证了驱动器在驱动和制动模式下的优越性能。

Conclusion: 双层静电薄膜驱动器在驱动性能和制动能力方面都有显著提升，为轻量紧凑机器人平台提供了有效的解决方案。

Abstract: Robotic systems driven by conventional motors often suffer from challenges such as large mass, complex control algorithms, and the need for additional braking mechanisms, which limit their applications in lightweight and compact robotic platforms. Electrostatic film actuators offer several advantages, including thinness, flexibility, lightweight construction, and high open-loop positioning accuracy. However, the actuation stress exhibited by conventional actuators in air still needs improvement, particularly for the widely used three-phase electrode design. To enhance the output performance of actuators, this paper presents a two-layer electrostatic film actuator with an integrated brake. By alternately distributing electrodes on both the top and bottom layers, a smaller effective electrode pitch is achieved under the same fabrication constraints, resulting in an actuation stress of approximately 241~N/m$^2$, representing a 90.5\% improvement over previous three-phase actuators operating in air. Furthermore, its integrated electrostatic adhesion mechanism enables load retention under braking mode. Several demonstrations, including a tug-of-war between a conventional single-layer actuator and the proposed two-layer actuator, a payload operation, a one-degree-of-freedom robotic arm, and a dual-mode gripper, were conducted to validate the actuator's advantageous capabilities in both actuation and braking modes.

</details>


### [6] [Human Motion Intent Inferencing in Teleoperation Through a SINDy Paradigm](https://arxiv.org/abs/2511.08377)
*Michael Bowman,Xiaoli Zhang*

Main category: cs.RO

TL;DR: Psychic框架通过跳跃-漂移-扩散随机微分方程建模操作者运动中的细微跳跃动作，结合Kramers-Moyal系数和统计异常检测来识别目标转换，使用SINDy模型推断操作者在非结构化场景中的运动行为。


<details>
  <summary>Details</summary>
Motivation: 当前意图推断方法往往忽略细微运动变化，而这些变化可能是意图突然改变的强有力指标。研究旨在解决：1）检测操作者轨迹中的突然跳跃；2）利用这些跳跃动作推断操作者的目标状态；3）结合不连续和连续动态推断操作者运动。

Method: 提出Psychic框架，使用跳跃-漂移-扩散随机微分方程建模不连续和连续动态，通过Kramers-Moyal系数检测跳跃，结合统计异常检测算法提名目标转换，应用SINDy模型推断操作者运动行为。

Result: Psychic能够生成概率可达集，在600个操作者轨迹的回顾性研究中验证了其有效性，能够早期检测现有目标并在非结构化场景中发现未定义目标。

Conclusion: Psychic框架通过建模细微跳跃动作，有效解决了遥操作中意图推断的问题，在离线和在线学习中均表现出良好性能，为操作者运动行为推断提供了新方法。

Abstract: Intent inferencing in teleoperation has been instrumental in aligning operator goals and coordinating actions with robotic partners. However, current intent inference methods often ignore subtle motion that can be strong indicators for a sudden change in intent. Specifically, we aim to tackle 1) if we can detect sudden jumps in operator trajectories, 2) how we appropriately use these sudden jump motions to infer an operator's goal state, and 3) how to incorporate these discontinuous and continuous dynamics to infer operator motion. Our framework, called Psychic, models these small indicative motions through a jump-drift-diffusion stochastic differential equation to cover discontinuous and continuous dynamics. Kramers-Moyal (KM) coefficients allow us to detect jumps with a trajectory which we pair with a statistical outlier detection algorithm to nominate goal transitions. Through identifying jumps, we can perform early detection of existing goals and discover undefined goals in unstructured scenarios. Our framework then applies a Sparse Identification of Nonlinear Dynamics (SINDy) model using KM coefficients with the goal transitions as a control input to infer an operator's motion behavior in unstructured scenarios. We demonstrate Psychic can produce probabilistic reachability sets and compare our strategy to a negative log-likelihood model fit. We perform a retrospective study on 600 operator trajectories in a hands-free teleoperation task to evaluate the efficacy of our opensource package, Psychic, in both offline and online learning.

</details>


### [7] [Intuitive control of supernumerary robotic limbs through a tactile-encoded neural interface](https://arxiv.org/abs/2511.08454)
*Tianyu Jia,Xingchen Yang,Ciaran McGeady,Yifeng Li,Jinzhi Lin,Kit San Ho,Feiyu Pan,Linhong Ji,Chong Li,Dario Farina*

Main category: cs.RO

TL;DR: 提出了一种基于触觉编码的脑机接口，通过触觉诱发P300范式实现超限运动意图的直观可靠解码，可在不干扰自然运动的情况下扩展运动自由度。


<details>
  <summary>Details</summary>
Motivation: 解决脑机接口在扩展人类运动能力时面临的挑战——如何在不干扰自然运动的情况下整合具有多个自由度的增强指令。

Method: 采用触觉编码的脑机接口，利用新型触觉诱发P300范式，通过刺激感觉传入神经来解码超限运动意图。在多日实验中评估单任务和双任务条件下的性能。

Result: 实现了四个超限自由度的实时可靠解码，仅三天训练后性能显著提升。训练后单双任务性能无显著差异，自然运动在并发超限控制时保持不受影响。成功应用于双手机器人臂的功能辅助任务。

Conclusion: 建立了一种通过刺激感觉传入神经实现运动增强的新神经接口范式，可在不损害自然运动的情况下扩展运动自由度。

Abstract: Brain-computer interfaces (BCIs) promise to extend human movement capabilities by enabling direct neural control of supernumerary effectors, yet integrating augmented commands with multiple degrees of freedom without disrupting natural movement remains a key challenge. Here, we propose a tactile-encoded BCI that leverages sensory afferents through a novel tactile-evoked P300 paradigm, allowing intuitive and reliable decoding of supernumerary motor intentions even when superimposed with voluntary actions. The interface was evaluated in a multi-day experiment comprising of a single motor recognition task to validate baseline BCI performance and a dual task paradigm to assess the potential influence between the BCI and natural human movement. The brain interface achieved real-time and reliable decoding of four supernumerary degrees of freedom, with significant performance improvements after only three days of training. Importantly, after training, performance did not differ significantly between the single- and dual-BCI task conditions, and natural movement remained unimpaired during concurrent supernumerary control. Lastly, the interface was deployed in a movement augmentation task, demonstrating its ability to command two supernumerary robotic arms for functional assistance during bimanual tasks. These results establish a new neural interface paradigm for movement augmentation through stimulation of sensory afferents, expanding motor degrees of freedom without impairing natural movement.

</details>


### [8] [Safe and Optimal Learning from Preferences via Weighted Temporal Logic with Applications in Robotics and Formula 1](https://arxiv.org/abs/2511.08502)
*Ruya Karagulle,Cristian-Ioan Vasile,Necmiye Ozay*

Main category: cs.RO

TL;DR: 提出了一种基于加权信号时序逻辑（WSTL）的安全保证学习方法，用于从偏好、排名或演示中学习，通过结构剪枝和对数变换将问题转化为混合整数线性规划，确保安全性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在安全关键领域中往往无法保证安全性，需要一种既能适应行为又能提供安全保证的学习方法。

Method: 使用加权信号时序逻辑（WSTL）框架，通过结构剪枝和对数变换将多线性约束问题转化为混合整数线性规划问题。

Result: 在机器人导航和真实世界F1数据上的实验表明，该方法能有效捕捉细微偏好并建模复杂任务目标。

Conclusion: 该方法提供了一种安全保证、最优且高效的学习方法，适用于从偏好、排名或演示中学习的安全关键应用。

Abstract: Autonomous systems increasingly rely on human feedback to align their behavior, expressed as pairwise comparisons, rankings, or demonstrations. While existing methods can adapt behaviors, they often fail to guarantee safety in safety-critical domains. We propose a safety-guaranteed, optimal, and efficient approach to solve the learning problem from preferences, rankings, or demonstrations using Weighted Signal Temporal Logic (WSTL). WSTL learning problems, when implemented naively, lead to multi-linear constraints in the weights to be learned. By introducing structural pruning and log-transform procedures, we reduce the problem size and recast the problem as a Mixed-Integer Linear Program while preserving safety guarantees. Experiments on robotic navigation and real-world Formula 1 data demonstrate that the method effectively captures nuanced preferences and models complex task objectives.

</details>


### [9] [SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment](https://arxiv.org/abs/2511.08583)
*Rong Xue,Jiageng Mao,Mingtong Zhang,Yue Wang*

Main category: cs.RO

TL;DR: SeFA提出了一种选择性流对齐策略，通过专家演示选择性校正生成的动作以保持与观察的一致性，解决了现有整流流方法中动作偏离地面真实值的问题。


<details>
  <summary>Details</summary>
Motivation: 现有整流流方法在迭代蒸馏后，生成的动作可能偏离当前视觉观察对应的地面真实动作，导致累积误差和不稳定的任务执行。

Method: 采用选择性流对齐策略，利用专家演示选择性校正生成动作并恢复与观察的一致性，同时保持多模态性，引入一致性校正机制。

Result: 在模拟和真实世界操作任务上的实验表明，SeFA策略超越了最先进的基于扩散和流的策略，实现了更高的准确性和鲁棒性，同时将推理延迟降低了98%以上。

Conclusion: SeFA通过统一整流流效率与观察一致的动作生成，为实时视觉运动策略学习提供了可扩展且可靠的解决方案。

Abstract: Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the ground-truth actions corresponding to the current visual observation, leading to accumulated error as the reflow process repeats and unstable task execution. We present Selective Flow Alignment (SeFA), an efficient and accurate visuomotor policy learning framework. SeFA resolves this challenge by a selective flow alignment strategy, which leverages expert demonstrations to selectively correct generated actions and restore consistency with observations, while preserving multimodality. This design introduces a consistency correction mechanism that ensures generated actions remain observation-aligned without sacrificing the efficiency of one-step flow inference. Extensive experiments across both simulated and real-world manipulation tasks show that SeFA Policy surpasses state-of-the-art diffusion-based and flow-based policies, achieving superior accuracy and robustness while reducing inference latency by over 98%. By unifying rectified flow efficiency with observation-consistent action generation, SeFA provides a scalable and dependable solution for real-time visuomotor policy learning. Code is available on https://github.com/RongXueZoe/SeFA.

</details>
